# Communication Without Movement: EEG Text Generation/Autosuggestion with Natural Language Processing in the Immobilized

This technology addressed an engineering, machine learning solution that allowed immobilized patients to communicate with others through text, further providing a noninvasive electroencephalography (EEG) headset to predict words from user brain signals. Previous studies, including the UCSF Speech Neuroprosthesis project led by Dr. Edward Chang, have required electrode implantations onto areas of a patient’s brain; however, a more user-friendly approach was applied to this solution using natural language processing. The LSTM (Long Short Term Memory) network models were placed as a back-end to display word suggestions based on previous phrases typed by the user; subsequently, the user selected a target suggestion or continued with another letter in the typing process. The EEG brain signals model had a calibration accuracy of 100%, while the prediction phase had an accuracy of 95% in identifying the correct letters on the screen. The “next word” model, which provided five suggestions for the next word of the text after a space, had 65% accuracy, while the “current word” model, which provides five suggestions to fill out the current word of the text, had 46% accuracy. Further advancements to the task of brain-to-word prediction can be applied by removing the visual stimulus necessary for user letter prediction, which would make the program far more user friendly. A visual screen that would light up the letters at different points in time would be helpful in predicting the correct letter that the user focuses on.

## Description
* Forked repository from MindAffect with NLP Autosuggestion
* [Demonstration video](bit.ly/2022SynopsysDemonstration)
* [MindAffect docs](https://github.com/mindaffect/pymindaffectBCI)
